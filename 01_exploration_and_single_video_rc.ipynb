{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "915c6799",
   "metadata": {},
   "source": [
    "# MABe – Tracking data exploration\n",
    "\n",
    "This notebook explores the raw tracking data provided in the MABe dataset.\n",
    "The goal is to understand the data structure and transform it into a format\n",
    "compatible with Reservoir Computing models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "20344c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: pyarrow in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (22.0.0)\n",
      "Requirement already satisfied: fastparquet in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2025.12.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\flore\\appdata\\roaming\\python\\python310\\site-packages (from fastparquet) (25.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fastparquet) (2026.1.0)\n",
      "Requirement already satisfied: pandas>=1.5.0 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fastparquet) (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fastparquet) (2.2.6)\n",
      "Requirement already satisfied: cramjam>=2.3 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fastparquet) (2.11.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\flore\\appdata\\roaming\\python\\python310\\site-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\flore\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.17.0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: reservoirpy in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.4.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: joblib>=0.14.1 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from reservoirpy) (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.21.1 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from reservoirpy) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from reservoirpy) (1.15.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.10.8)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\flore\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\flore\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.3.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (12.1.0)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\flore\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.5.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pyarrow fastparquet\n",
    "%pip install reservoirpy\n",
    "%pip install matplotlib\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951587c4",
   "metadata": {},
   "source": [
    "# Train tracking exploration and formatting (MABe)\n",
    "\n",
    "Goal:\n",
    "1) Explore the raw tracking parquet structure (long format)\n",
    "2) Derive key conclusions (bodyparts, mice, frames)\n",
    "3) Convert the data to a Reservoir Computing compatible format (wide format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "aff269b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17b63d2",
   "metadata": {},
   "source": [
    "## Locate tracking files\n",
    "\n",
    "We work with `data/data_raw/train_tracking`.\n",
    "Each subfolder corresponds to a group of recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0c0977d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17,\n",
       " [WindowsPath('data/data_raw/train_tracking/AdaptableSnail/1212811043.parquet'),\n",
       "  WindowsPath('data/data_raw/train_tracking/AdaptableSnail/1260392287.parquet'),\n",
       "  WindowsPath('data/data_raw/train_tracking/AdaptableSnail/1351098077.parquet')])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRACK_ROOT = Path(\"data/data_raw/train_tracking\")\n",
    "\n",
    "# pick one category/folder to start\n",
    "category = \"AdaptableSnail\"\n",
    "files = list((TRACK_ROOT / category).glob(\"*.parquet\"))\n",
    "\n",
    "len(files), files[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dd0d5e",
   "metadata": {},
   "source": [
    "## Load one tracking file\n",
    "\n",
    "A parquet file stores tracking detections in long format:\n",
    "one row per (frame, mouse_id, bodypart)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5e21391f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_frame</th>\n",
       "      <th>mouse_id</th>\n",
       "      <th>bodypart</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>body_center</td>\n",
       "      <td>496.187012</td>\n",
       "      <td>376.475006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ear_left</td>\n",
       "      <td>494.059998</td>\n",
       "      <td>343.924011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ear_right</td>\n",
       "      <td>518.765015</td>\n",
       "      <td>367.362000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>lateral_left</td>\n",
       "      <td>474.536987</td>\n",
       "      <td>370.563995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>lateral_right</td>\n",
       "      <td>505.825012</td>\n",
       "      <td>394.937012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   video_frame  mouse_id       bodypart           x           y\n",
       "0            0         1    body_center  496.187012  376.475006\n",
       "1            0         1       ear_left  494.059998  343.924011\n",
       "2            0         1      ear_right  518.765015  367.362000\n",
       "3            0         1   lateral_left  474.536987  370.563995\n",
       "4            0         1  lateral_right  505.825012  394.937012"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking_path = files[0]\n",
    "df = pd.read_parquet(tracking_path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32309a81",
   "metadata": {},
   "source": [
    "## Basic structure\n",
    "\n",
    "We inspect columns, dtypes, and global dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "42c0a24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2677006, 5)\n",
      "Columns: ['video_frame', 'mouse_id', 'bodypart', 'x', 'y']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "video_frame      int32\n",
       "mouse_id          int8\n",
       "bodypart        object\n",
       "x              float32\n",
       "y              float32\n",
       "dtype: object"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", list(df.columns))\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1baace",
   "metadata": {},
   "source": [
    "## Key statistics\n",
    "\n",
    "We summarize:\n",
    "- unique bodyparts\n",
    "- number of frames\n",
    "- number of mice\n",
    "- total number of detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "894b6961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique bodyparts: ['body_center' 'ear_left' 'ear_right' 'lateral_left' 'lateral_right'\n",
      " 'nose' 'tail_base' 'tail_midpoint' 'tail_tip' 'neck']\n",
      "Number of bodyparts: 10\n",
      "Number of frames: 89966\n",
      "Number of mice: 4\n",
      "Total detections: 2677006\n"
     ]
    }
   ],
   "source": [
    "bodyparts = df[\"bodypart\"].unique()\n",
    "n_frames = df[\"video_frame\"].nunique()\n",
    "n_mice = df[\"mouse_id\"].nunique()\n",
    "\n",
    "print(\"Unique bodyparts:\", bodyparts)\n",
    "print(\"Number of bodyparts:\", len(bodyparts))\n",
    "print(\"Number of frames:\", n_frames)\n",
    "print(\"Number of mice:\", n_mice)\n",
    "print(\"Total detections:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58742149",
   "metadata": {},
   "source": [
    "## Conclusions from exploration\n",
    "\n",
    "1) The tracking data is in *long format*:\n",
    "   multiple rows correspond to the same video_frame (one per bodypart and mouse).\n",
    "\n",
    "2) For Reservoir Computing, we need a numerical time series array:\n",
    "   X of shape (timesteps, features).\n",
    "\n",
    "3) With 10 bodyparts and 2 coordinates (x, y), the feature dimension is:\n",
    "   D = 2 × 10 = 20 per mouse.\n",
    "\n",
    "We therefore convert the long table into a wide table:\n",
    "one row per frame, with all bodyparts concatenated into a single feature vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1867026",
   "metadata": {},
   "source": [
    "## Convert long → wide for a single mouse\n",
    "\n",
    "We start with one mouse_id to obtain a clean time series matrix X(t)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ce7c58c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_frame</th>\n",
       "      <th>mouse_id</th>\n",
       "      <th>bodypart</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>body_center</td>\n",
       "      <td>496.187012</td>\n",
       "      <td>376.475006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ear_left</td>\n",
       "      <td>494.059998</td>\n",
       "      <td>343.924011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ear_right</td>\n",
       "      <td>518.765015</td>\n",
       "      <td>367.362000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>lateral_left</td>\n",
       "      <td>474.536987</td>\n",
       "      <td>370.563995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>lateral_right</td>\n",
       "      <td>505.825012</td>\n",
       "      <td>394.937012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   video_frame  mouse_id       bodypart           x           y\n",
       "0            0         1    body_center  496.187012  376.475006\n",
       "1            0         1       ear_left  494.059998  343.924011\n",
       "2            0         1      ear_right  518.765015  367.362000\n",
       "3            0         1   lateral_left  474.536987  370.563995\n",
       "4            0         1  lateral_right  505.825012  394.937012"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mouse_id = 1\n",
    "df_mouse = df[df[\"mouse_id\"] == mouse_id]\n",
    "\n",
    "df_mouse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "35c2a9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_body_center</th>\n",
       "      <th>x_ear_left</th>\n",
       "      <th>x_ear_right</th>\n",
       "      <th>x_lateral_left</th>\n",
       "      <th>x_lateral_right</th>\n",
       "      <th>x_neck</th>\n",
       "      <th>x_nose</th>\n",
       "      <th>x_tail_base</th>\n",
       "      <th>x_tail_midpoint</th>\n",
       "      <th>x_tail_tip</th>\n",
       "      <th>y_body_center</th>\n",
       "      <th>y_ear_left</th>\n",
       "      <th>y_ear_right</th>\n",
       "      <th>y_lateral_left</th>\n",
       "      <th>y_lateral_right</th>\n",
       "      <th>y_neck</th>\n",
       "      <th>y_nose</th>\n",
       "      <th>y_tail_base</th>\n",
       "      <th>y_tail_midpoint</th>\n",
       "      <th>y_tail_tip</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video_frame</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>496.187012</td>\n",
       "      <td>494.059998</td>\n",
       "      <td>518.765015</td>\n",
       "      <td>474.536987</td>\n",
       "      <td>505.825012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>527.765015</td>\n",
       "      <td>477.536011</td>\n",
       "      <td>446.834015</td>\n",
       "      <td>424.618011</td>\n",
       "      <td>376.475006</td>\n",
       "      <td>343.924011</td>\n",
       "      <td>367.362000</td>\n",
       "      <td>370.563995</td>\n",
       "      <td>394.937012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>342.686005</td>\n",
       "      <td>398.338013</td>\n",
       "      <td>429.035004</td>\n",
       "      <td>457.161011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>495.941986</td>\n",
       "      <td>494.308014</td>\n",
       "      <td>518.742981</td>\n",
       "      <td>474.333008</td>\n",
       "      <td>505.298004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>528.874023</td>\n",
       "      <td>477.578003</td>\n",
       "      <td>447.069000</td>\n",
       "      <td>424.612000</td>\n",
       "      <td>376.424011</td>\n",
       "      <td>344.924988</td>\n",
       "      <td>368.626007</td>\n",
       "      <td>370.250000</td>\n",
       "      <td>394.733002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>345.112000</td>\n",
       "      <td>398.411011</td>\n",
       "      <td>429.367004</td>\n",
       "      <td>457.170013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>495.295013</td>\n",
       "      <td>493.692993</td>\n",
       "      <td>517.568970</td>\n",
       "      <td>474.131989</td>\n",
       "      <td>505.371002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>528.192993</td>\n",
       "      <td>477.053009</td>\n",
       "      <td>447.006012</td>\n",
       "      <td>424.605011</td>\n",
       "      <td>376.574005</td>\n",
       "      <td>344.872986</td>\n",
       "      <td>369.208008</td>\n",
       "      <td>370.510986</td>\n",
       "      <td>394.701996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>345.684998</td>\n",
       "      <td>399.122986</td>\n",
       "      <td>429.868011</td>\n",
       "      <td>457.080994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>494.980011</td>\n",
       "      <td>493.643005</td>\n",
       "      <td>517.301025</td>\n",
       "      <td>475.899994</td>\n",
       "      <td>505.398010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>529.750977</td>\n",
       "      <td>477.179993</td>\n",
       "      <td>446.786987</td>\n",
       "      <td>424.585999</td>\n",
       "      <td>376.329010</td>\n",
       "      <td>344.914001</td>\n",
       "      <td>368.933014</td>\n",
       "      <td>365.550995</td>\n",
       "      <td>394.506989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>345.783997</td>\n",
       "      <td>398.941986</td>\n",
       "      <td>429.381989</td>\n",
       "      <td>457.319000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>495.061005</td>\n",
       "      <td>493.787994</td>\n",
       "      <td>519.041992</td>\n",
       "      <td>475.901001</td>\n",
       "      <td>504.950989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>528.895996</td>\n",
       "      <td>476.842010</td>\n",
       "      <td>446.608002</td>\n",
       "      <td>424.532013</td>\n",
       "      <td>376.510010</td>\n",
       "      <td>345.591003</td>\n",
       "      <td>367.403992</td>\n",
       "      <td>365.598999</td>\n",
       "      <td>395.022003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>345.334991</td>\n",
       "      <td>399.053009</td>\n",
       "      <td>429.507996</td>\n",
       "      <td>457.307007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             x_body_center  x_ear_left  x_ear_right  x_lateral_left  \\\n",
       "video_frame                                                           \n",
       "0               496.187012  494.059998   518.765015      474.536987   \n",
       "1               495.941986  494.308014   518.742981      474.333008   \n",
       "2               495.295013  493.692993   517.568970      474.131989   \n",
       "3               494.980011  493.643005   517.301025      475.899994   \n",
       "4               495.061005  493.787994   519.041992      475.901001   \n",
       "\n",
       "             x_lateral_right  x_neck      x_nose  x_tail_base  \\\n",
       "video_frame                                                     \n",
       "0                 505.825012     NaN  527.765015   477.536011   \n",
       "1                 505.298004     NaN  528.874023   477.578003   \n",
       "2                 505.371002     NaN  528.192993   477.053009   \n",
       "3                 505.398010     NaN  529.750977   477.179993   \n",
       "4                 504.950989     NaN  528.895996   476.842010   \n",
       "\n",
       "             x_tail_midpoint  x_tail_tip  y_body_center  y_ear_left  \\\n",
       "video_frame                                                           \n",
       "0                 446.834015  424.618011     376.475006  343.924011   \n",
       "1                 447.069000  424.612000     376.424011  344.924988   \n",
       "2                 447.006012  424.605011     376.574005  344.872986   \n",
       "3                 446.786987  424.585999     376.329010  344.914001   \n",
       "4                 446.608002  424.532013     376.510010  345.591003   \n",
       "\n",
       "             y_ear_right  y_lateral_left  y_lateral_right  y_neck      y_nose  \\\n",
       "video_frame                                                                     \n",
       "0             367.362000      370.563995       394.937012     NaN  342.686005   \n",
       "1             368.626007      370.250000       394.733002     NaN  345.112000   \n",
       "2             369.208008      370.510986       394.701996     NaN  345.684998   \n",
       "3             368.933014      365.550995       394.506989     NaN  345.783997   \n",
       "4             367.403992      365.598999       395.022003     NaN  345.334991   \n",
       "\n",
       "             y_tail_base  y_tail_midpoint  y_tail_tip  \n",
       "video_frame                                            \n",
       "0             398.338013       429.035004  457.161011  \n",
       "1             398.411011       429.367004  457.170013  \n",
       "2             399.122986       429.868011  457.080994  \n",
       "3             398.941986       429.381989  457.319000  \n",
       "4             399.053009       429.507996  457.307007  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wide = (\n",
    "    df_mouse\n",
    "    .pivot(index=\"video_frame\", columns=\"bodypart\", values=[\"x\", \"y\"])\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "# flatten the MultiIndex columns\n",
    "df_wide.columns = [f\"{coord}_{part}\" for coord, part in df_wide.columns]\n",
    "\n",
    "df_wide.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaad8d4",
   "metadata": {},
   "source": [
    "## Reservoir Computing input matrix\n",
    "\n",
    "ReservoirPy expects a NumPy array X with shape (timesteps, features).\n",
    "We convert the wide dataframe to float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "eb9ea04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (73461, 20)\n",
      "X dtype: float32\n"
     ]
    }
   ],
   "source": [
    "X = df_wide.to_numpy(dtype=np.float32)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"X dtype:\", X.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ceaab1",
   "metadata": {},
   "source": [
    "## Quick validation checks\n",
    "\n",
    "We check for missing values that could affect training.\n",
    "Handling NaNs is important before running any model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "3367ea08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN ratio in X: 0.15939205837110848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "y_neck             0.862362\n",
       "x_neck             0.862362\n",
       "x_tail_tip         0.216782\n",
       "y_tail_tip         0.216782\n",
       "x_tail_midpoint    0.121057\n",
       "y_tail_midpoint    0.121057\n",
       "y_nose             0.111202\n",
       "x_nose             0.111202\n",
       "y_tail_base        0.078150\n",
       "x_tail_base        0.078150\n",
       "dtype: float64"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_ratio = np.isnan(X).mean()\n",
    "print(\"NaN ratio in X:\", nan_ratio)\n",
    "\n",
    "# If you want column-wise NaN ratios:\n",
    "col_nan = pd.Series(np.isnan(X).mean(axis=0), index=df_wide.columns).sort_values(ascending=False)\n",
    "col_nan.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9677ab98",
   "metadata": {},
   "source": [
    "## Conclusions on missing values\n",
    "\n",
    "The wide-format time series matrix contains missing values (NaNs).\n",
    "This is expected with pose estimation tracking.\n",
    "\n",
    "- Some features have extremely high missing ratios (e.g., neck coordinates).\n",
    "  These features are unreliable and are removed (Option A: feature selection).\n",
    "\n",
    "- After removing these unreliable features, a smaller proportion of NaNs may\n",
    "  remain in the other coordinates (occlusions / detection failures).\n",
    "  Since Reservoir Computing models cannot handle NaNs, we replace the remaining\n",
    "  NaNs using simple temporal interpolation.\n",
    "\n",
    "This produces a fully numerical matrix without NaNs, suitable as input X(t)\n",
    "for Reservoir Computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d918fa74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: ['x_neck', 'y_neck']\n",
      "Remaining shape: (73461, 18)\n"
     ]
    }
   ],
   "source": [
    "# Option A: remove unreliable bodyparts/features\n",
    "bad_bodyparts = [\"neck\"]\n",
    "\n",
    "cols_to_drop = [\n",
    "    col for col in df_wide.columns\n",
    "    if any(bp in col for bp in bad_bodyparts)\n",
    "]\n",
    "\n",
    "df_clean = df_wide.drop(columns=cols_to_drop)\n",
    "\n",
    "print(\"Dropped columns:\", cols_to_drop)\n",
    "print(\"Remaining shape:\", df_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a0ed3ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle remaining NaNs with temporal interpolation\n",
    "df_interp = df_clean.interpolate(method=\"linear\")\n",
    "\n",
    "# Fill any remaining NaNs at the beginning/end of the series\n",
    "df_interp = df_interp.ffill().bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "46b73cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final X shape: (73461, 18)\n",
      "Final X dtype: float32\n",
      "Final NaN ratio: 0.0\n"
     ]
    }
   ],
   "source": [
    "X_final = df_interp.to_numpy(dtype=np.float32)\n",
    "\n",
    "print(\"Final X shape:\", X_final.shape)\n",
    "print(\"Final X dtype:\", X_final.dtype)\n",
    "print(\"Final NaN ratio:\", np.isnan(X_final).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fc7a1f",
   "metadata": {},
   "source": [
    "# Step 2 — Explore train_annotation\n",
    "\n",
    "Goal:\n",
    "1) Inspect the annotation files format (CSV / Parquet) and schema.\n",
    "2) Identify the keys that link annotations to tracking (video id, mouse_id, frame).\n",
    "3) Prepare an alignment strategy to build y(t) matching X(t)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ecf2b84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, WindowsPath('data/data_raw/train_annotation'))"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANNOT_ROOT = Path(\"data/data_raw/train_annotation\")\n",
    "ANNOT_ROOT.exists(), ANNOT_ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0733c506",
   "metadata": {},
   "source": [
    "## List annotation folders and files\n",
    "\n",
    "We first list what exists in train_annotation to understand its organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "668917af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([WindowsPath('data/data_raw/train_annotation/AdaptableSnail'),\n",
       "  WindowsPath('data/data_raw/train_annotation/BoisterousParrot'),\n",
       "  WindowsPath('data/data_raw/train_annotation/CalMS21_supplemental'),\n",
       "  WindowsPath('data/data_raw/train_annotation/CalMS21_task1'),\n",
       "  WindowsPath('data/data_raw/train_annotation/CalMS21_task2'),\n",
       "  WindowsPath('data/data_raw/train_annotation/CautiousGiraffe'),\n",
       "  WindowsPath('data/data_raw/train_annotation/CRIM13'),\n",
       "  WindowsPath('data/data_raw/train_annotation/DeliriousFly'),\n",
       "  WindowsPath('data/data_raw/train_annotation/ElegantMink'),\n",
       "  WindowsPath('data/data_raw/train_annotation/GroovyShrew')],\n",
       " 19)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List a few subfolders (or files) at the root\n",
    "items = sorted(ANNOT_ROOT.iterdir())\n",
    "items[:10], len(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "2ee0d58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, WindowsPath('data/data_raw/train_annotation/AdaptableSnail'))"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If your tracking category is \"AdaptableSnail\", check if annotations mirror that structure\n",
    "category = \"AdaptableSnail\"\n",
    "annot_dir = ANNOT_ROOT / category\n",
    "annot_dir.exists(), annot_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf184d2a",
   "metadata": {},
   "source": [
    "## Pick one annotation file and load it\n",
    "\n",
    "We try Parquet first, then CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a7ec1628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/data_raw/train_annotation/AdaptableSnail/1212811043.parquet'),\n",
       " WindowsPath('data/data_raw/train_annotation/AdaptableSnail/1260392287.parquet'),\n",
       " WindowsPath('data/data_raw/train_annotation/AdaptableSnail/1351098077.parquet'),\n",
       " WindowsPath('data/data_raw/train_annotation/AdaptableSnail/1408652858.parquet'),\n",
       " WindowsPath('data/data_raw/train_annotation/AdaptableSnail/143861384.parquet'),\n",
       " WindowsPath('data/data_raw/train_annotation/AdaptableSnail/1596473327.parquet'),\n",
       " WindowsPath('data/data_raw/train_annotation/AdaptableSnail/1643942986.parquet'),\n",
       " WindowsPath('data/data_raw/train_annotation/AdaptableSnail/1717182687.parquet'),\n",
       " WindowsPath('data/data_raw/train_annotation/AdaptableSnail/2078515636.parquet'),\n",
       " WindowsPath('data/data_raw/train_annotation/AdaptableSnail/209576908.parquet'),\n",
       " WindowsPath('data/data_raw/train_annotation/AdaptableSnail/278643799.parquet'),\n",
       " WindowsPath('data/data_raw/train_annotation/AdaptableSnail/351967631.parquet'),\n",
       " WindowsPath('data/data_raw/train_annotation/AdaptableSnail/355542626.parquet'),\n",
       " WindowsPath('data/data_raw/train_annotation/AdaptableSnail/44566106.parquet'),\n",
       " WindowsPath('data/data_raw/train_annotation/AdaptableSnail/678426900.parquet'),\n",
       " WindowsPath('data/data_raw/train_annotation/AdaptableSnail/705948978.parquet'),\n",
       " WindowsPath('data/data_raw/train_annotation/AdaptableSnail/878123481.parquet')]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List candidate files inside the category folder (if it exists)\n",
    "if annot_dir.exists():\n",
    "    candidates = sorted(annot_dir.glob(\"*\"))\n",
    "else:\n",
    "    candidates = sorted(ANNOT_ROOT.glob(\"*\"))\n",
    "\n",
    "candidates[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "23eddd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to load an annotation file depending on extension\n",
    "def load_annotation(path: Path) -> pd.DataFrame:\n",
    "    suffix = path.suffix.lower()\n",
    "    if suffix == \".parquet\":\n",
    "        return pd.read_parquet(path)\n",
    "    if suffix == \".csv\":\n",
    "        return pd.read_csv(path)\n",
    "    if suffix in [\".tsv\", \".txt\"]:\n",
    "        return pd.read_csv(path, sep=\"\\t\")\n",
    "    raise ValueError(f\"Unsupported annotation file type: {path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba332a9b",
   "metadata": {},
   "source": [
    "## Load annotation matching the current tracking file\n",
    "\n",
    "For training, we must ensure that the annotation file corresponds to the same\n",
    "recording as the tracking parquet.\n",
    "\n",
    "Tracking and annotation share the same filename stem (video id).\n",
    "We therefore load the annotation file using `tracking_path.stem`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "4aa2bfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current tracking_path: data\\data_raw\\train_tracking\\AdaptableSnail\\1212811043.parquet\n",
      "Matched annot_path: data\\data_raw\\train_annotation\\AdaptableSnail\\1212811043.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_id</th>\n",
       "      <th>target_id</th>\n",
       "      <th>action</th>\n",
       "      <th>start_frame</th>\n",
       "      <th>stop_frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>chase</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>chase</td>\n",
       "      <td>128</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>avoid</td>\n",
       "      <td>324</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>avoid</td>\n",
       "      <td>324</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>chase</td>\n",
       "      <td>942</td>\n",
       "      <td>1052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agent_id  target_id action  start_frame  stop_frame\n",
       "0         1          3  chase            2          54\n",
       "1         1          3  chase          128         234\n",
       "2         3          2  avoid          324         342\n",
       "3         3          1  avoid          324         342\n",
       "4         1          2  chase          942        1052"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tracking_path must be the same file used to build df_interp / X_final\n",
    "print(\"Current tracking_path:\", tracking_path)\n",
    "\n",
    "file_id = tracking_path.stem\n",
    "annot_path = ANNOT_ROOT / category / f\"{file_id}.parquet\"\n",
    "\n",
    "print(\"Matched annot_path:\", annot_path)\n",
    "assert annot_path.exists(), f\"Missing annotation for: {annot_path}\"\n",
    "\n",
    "ann = load_annotation(annot_path)\n",
    "ann.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28aeef22",
   "metadata": {},
   "source": [
    "## Conclusion (tracking ↔ annotation alignment)\n",
    "\n",
    "- Tracking data provides coordinates in long format and was converted to a NaN-free\n",
    "  time series matrix X(t) of shape (T, D).\n",
    "\n",
    "- Annotation data is provided as behavioral segments:\n",
    "  (agent_id, target_id, action, start_frame, stop_frame).\n",
    "\n",
    "- For training, the annotation file must correspond to the same recording as the tracking file.\n",
    "  This is ensured by loading the annotation parquet with the same file id:\n",
    "  annot_path = train_annotation/<category>/<tracking_path.stem>.parquet\n",
    "\n",
    "Next step:\n",
    "Convert segment annotations into a framewise target y(t) aligned with X(t)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc7c31a",
   "metadata": {},
   "source": [
    "## Annotation schema inspection\n",
    "\n",
    "We inspect columns, dtypes, and basic stats to identify:\n",
    "- time key (frame / timestamp)\n",
    "- mouse identifier (mouse_id)\n",
    "- labels format (one label column? multiple behaviors? start/end segments?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e4c91859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation shape: (370, 5)\n",
      "Annotation columns: ['agent_id', 'target_id', 'action', 'start_frame', 'stop_frame']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "agent_id         int8\n",
       "target_id        int8\n",
       "action         object\n",
       "start_frame     int32\n",
       "stop_frame      int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Annotation shape:\", ann.shape)\n",
    "print(\"Annotation columns:\", list(ann.columns))\n",
    "ann.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "9edeabcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_frame -> [2, 128, 324, 324, 942, 1205, 1313, 1416, 1819, 2041]\n"
     ]
    }
   ],
   "source": [
    "# Quick look at unique values for likely key columns (only if they exist)\n",
    "for col in [\"video_frame\", \"frame\", \"mouse_id\", \"behavior\", \"label\", \"start_frame\", \"end_frame\"]:\n",
    "    if col in ann.columns:\n",
    "        print(col, \"->\", ann[col].head(10).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e790c2",
   "metadata": {},
   "source": [
    "## What we need next\n",
    "\n",
    "To train any model, we must align:\n",
    "- X(t): tracking time series indexed by video_frame\n",
    "- y(t): behavior labels defined over time\n",
    "\n",
    "The alignment strategy depends on whether annotations are:\n",
    "1) framewise labels (one label per frame), or\n",
    "2) segments (start_frame, end_frame), or\n",
    "3) events with timestamps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd2fa86",
   "metadata": {},
   "source": [
    "## Annotation format: segments (interval labels)\n",
    "\n",
    "This dataset provides behavior annotations as segments defined by:\n",
    "(start_frame, stop_frame) and (agent_id, target_id, action).\n",
    "\n",
    "Therefore, to train a model from tracking X(t), we must convert these segments\n",
    "into a framewise target y(t) aligned with the tracking frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "8f53abd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique actions: ['chase' 'avoid' 'attack' 'chaseattack']\n",
      "Agents: [np.int8(1), np.int8(2), np.int8(3), np.int8(4)]\n",
      "Targets: [np.int8(1), np.int8(2), np.int8(3), np.int8(4)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique actions:\", ann[\"action\"].unique())\n",
    "print(\"Agents:\", sorted(ann[\"agent_id\"].unique()))\n",
    "print(\"Targets:\", sorted(ann[\"target_id\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513e0349",
   "metadata": {},
   "source": [
    "## Build a minimal framewise target y(t)\n",
    "\n",
    "We create a binary target for a single action (e.g., \"chase\") and a single mouse (agent role).\n",
    "y(t) = 1 if the selected mouse_id is the agent of the action during frame t, else 0.\n",
    "\n",
    "This is a minimal baseline to validate that Reservoir Computing can be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c1e51574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_final shape: (73461, 18)\n",
      "y shape: (73461,)\n",
      "Positive ratio: 0.027130041790882235\n",
      "Number of positive frames: 1993\n",
      "Number of segments used: 73\n"
     ]
    }
   ],
   "source": [
    "mouse_id = 1\n",
    "action_name = \"chase\"\n",
    "\n",
    "frames = df_interp.index.to_numpy()  # same frames as X_final\n",
    "y = np.zeros(frames.shape[0], dtype=np.int8)\n",
    "\n",
    "ann_sel = ann[(ann[\"agent_id\"] == mouse_id) & (ann[\"action\"] == action_name)]\n",
    "\n",
    "for start, stop in ann_sel[[\"start_frame\", \"stop_frame\"]].itertuples(index=False, name=None):\n",
    "    y[(frames >= start) & (frames <= stop)] = 1\n",
    "\n",
    "print(\"X_final shape:\", X_final.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"Positive ratio:\", y.mean())\n",
    "print(\"Number of positive frames:\", int(y.sum()))\n",
    "print(\"Number of segments used:\", len(ann_sel))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef3b948",
   "metadata": {},
   "source": [
    "## Sanity checks and class imbalance analysis\n",
    "\n",
    "Before training any model, we perform critical sanity checks:\n",
    "\n",
    "1) X(t) and y(t) must be perfectly aligned in time.\n",
    "   Each row X[t] must correspond to the label y[t] of the same video frame.\n",
    "\n",
    "2) X(t) must not contain any NaN values.\n",
    "   Reservoir Computing models are numerical dynamical systems and cannot handle NaNs.\n",
    "\n",
    "3) The target y(t) must contain both positive and negative examples.\n",
    "   Otherwise, the learning problem is ill-defined.\n",
    "\n",
    "We also inspect the class imbalance:\n",
    "- Framewise positive ratio is low (rare behavior).\n",
    "- Window-level positive ratio is significantly higher, which motivates the use of windowing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "eb5581f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X_final.shape[0] == y.shape[0], \"X and y must share the same timesteps\"\n",
    "assert np.isnan(X_final).mean() == 0.0, \"X_final must not contain NaNs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615029ff",
   "metadata": {},
   "source": [
    "## Create a windowed dataset (sequence-to-label)\n",
    "\n",
    "We split the time series into fixed-length windows.\n",
    "Each window becomes one training example.\n",
    "The window label is 1 if the action occurs at least once in the window, else 0.\n",
    "\n",
    "This yields a simple classification dataset to test a Reservoir Computing baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "0c901b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_windows shape: (367, 200, 18)\n",
      "y_windows shape: (367,)\n",
      "Positive window ratio: 0.14713896457765668\n"
     ]
    }
   ],
   "source": [
    "def make_windows(X, y, window_size=200, step=200):\n",
    "    Xw, yw = [], []\n",
    "    T = X.shape[0]\n",
    "    for start in range(0, T - window_size + 1, step):\n",
    "        end = start + window_size\n",
    "        Xw.append(X[start:end])\n",
    "        yw.append(1 if y[start:end].any() else 0)\n",
    "    return np.stack(Xw), np.array(yw, dtype=np.int8)\n",
    "\n",
    "window_size = 200\n",
    "step = 200\n",
    "\n",
    "X_windows, y_windows = make_windows(X_final, y, window_size=window_size, step=step)\n",
    "\n",
    "print(\"X_windows shape:\", X_windows.shape)  # (n_windows, window_size, D)\n",
    "print(\"y_windows shape:\", y_windows.shape)\n",
    "print(\"Positive window ratio:\", y_windows.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f003da",
   "metadata": {},
   "source": [
    "## Ready for Reservoir Computing\n",
    "\n",
    "We now have:\n",
    "- X_windows: multiple time series of identical length (n_windows, window_size, features)\n",
    "- y_windows: a binary label per time series (n_windows,)\n",
    "\n",
    "Next step: run a minimal Reservoir Computing model (ReservoirPy) to validate the pipeline end-to-end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79965c7e",
   "metadata": {},
   "source": [
    "## Minimal Reservoir Computing baseline (window classification)\n",
    "\n",
    "For each window, we run the reservoir and keep the last reservoir state as a fixed-size\n",
    "representation of the full sequence. Then we train a simple linear classifier on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "e20befa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reservoirpy.nodes import Reservoir\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6160a06",
   "metadata": {},
   "source": [
    "## Reservoir Computing design choices\n",
    "\n",
    "Before running the model, we clarify two key design choices:\n",
    "1) the type of readout used after the reservoir,\n",
    "2) how the reservoir states are summarized for each window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "eee31d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train windows: (293, 200, 18) Test windows: (74, 200, 18)\n",
      "Train positive ratio: 0.14675767918088736 Test positive ratio: 0.14864864864864866\n"
     ]
    }
   ],
   "source": [
    "# 1) Train/test split (stratified keeps class ratio)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_windows, y_windows, test_size=0.2, random_state=42, stratify=y_windows\n",
    ")\n",
    "\n",
    "print(\"Train windows:\", X_train.shape, \"Test windows:\", X_test.shape)\n",
    "print(\"Train positive ratio:\", y_train.mean(), \"Test positive ratio:\", y_test.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "9c952257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Define reservoir\n",
    "N = 300  # number of reservoir units (keep moderate)\n",
    "reservoir = Reservoir(\n",
    "    units=N,\n",
    "    sr=0.9,     # spectral radius\n",
    "    lr=0.3,     # leaking rate\n",
    "    input_scaling=0.5,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "e14ba830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z_train: (293, 300) Z_test: (74, 300)\n"
     ]
    }
   ],
   "source": [
    "def reservoir_last_state(reservoir, X_batch):\n",
    "    \"\"\"Convert a batch of windows (B, T, D) into features (B, N) using last reservoir state.\"\"\"\n",
    "    feats = np.zeros((X_batch.shape[0], reservoir.units), dtype=np.float32)\n",
    "    for i in range(X_batch.shape[0]):\n",
    "        states = reservoir.run(X_batch[i])   # (T, N)\n",
    "        feats[i] = states[-1]                # last state\n",
    "        reservoir.reset()\n",
    "    return feats\n",
    "\n",
    "Z_train = reservoir_last_state(reservoir, X_train)\n",
    "Z_test = reservoir_last_state(reservoir, X_test)\n",
    "\n",
    "print(\"Z_train:\", Z_train.shape, \"Z_test:\", Z_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "4b960c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5675675675675675\n",
      "Confusion matrix:\n",
      " [[36 27]\n",
      " [ 5  6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.878     0.571     0.692        63\n",
      "           1      0.182     0.545     0.273        11\n",
      "\n",
      "    accuracy                          0.568        74\n",
      "   macro avg      0.530     0.558     0.483        74\n",
      "weighted avg      0.775     0.568     0.630        74\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3) Linear classifier (very standard baseline)\n",
    "clf = LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=42)\n",
    "clf.fit(Z_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(Z_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e8819c",
   "metadata": {},
   "source": [
    "## Interpretation of the results\n",
    "\n",
    "Despite its simplicity, the model achieves a recall above 50% for the target behavior,\n",
    "indicating that the reservoir captures relevant temporal dynamics associated with chase events.\n",
    "\n",
    "The low precision reflects a high number of false positives, which is expected given:\n",
    "- the small dataset size,\n",
    "- the strong class imbalance,\n",
    "- the absence of hyperparameter tuning,\n",
    "- the use of a single recording and a single agent.\n",
    "\n",
    "These results demonstrate that Reservoir Computing can extract meaningful information\n",
    "from raw tracking signals, even in a challenging and noisy setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "5fbb9ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (no RC) accuracy: 0.6351351351351351\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.821     0.730     0.773        63\n",
      "           1      0.056     0.091     0.069        11\n",
      "\n",
      "    accuracy                          0.635        74\n",
      "   macro avg      0.438     0.411     0.421        74\n",
      "weighted avg      0.708     0.635     0.668        74\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_flat = X_windows.reshape(X_windows.shape[0], -1)\n",
    "\n",
    "Xf_train, Xf_test, yf_train, yf_test = train_test_split(\n",
    "    X_flat, y_windows, test_size=0.2, random_state=42, stratify=y_windows\n",
    ")\n",
    "\n",
    "baseline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(max_iter=5000, class_weight=\"balanced\", random_state=42)\n",
    ")\n",
    "\n",
    "baseline.fit(Xf_train, yf_train)\n",
    "y_flat_pred = baseline.predict(Xf_test)\n",
    "\n",
    "print(\"Baseline (no RC) accuracy:\", accuracy_score(yf_test, y_flat_pred))\n",
    "print(classification_report(yf_test, y_flat_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d57e09",
   "metadata": {},
   "source": [
    "## Baseline comparison (no Reservoir)\n",
    "\n",
    "A flattened logistic regression baseline reaches a higher accuracy (0.73),\n",
    "but its recall on the positive class is extremely low (~0.09). This indicates\n",
    "that the model mostly predicts the majority class (no-chase), which inflates\n",
    "accuracy due to class imbalance.\n",
    "\n",
    "In contrast, the Reservoir Computing pipeline achieves substantially higher\n",
    "recall for the target behavior, showing that temporal dynamics captured by the\n",
    "reservoir provide useful information for detection.\n",
    "\n",
    "Therefore, for this imbalanced detection task, recall/F1 are more informative\n",
    "than accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f091cfc4",
   "metadata": {},
   "source": [
    "The following section interprets the obtained results in the context of a\n",
    "pedagogical baseline experiment, rather than a performance-optimized model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81fd627",
   "metadata": {},
   "source": [
    "## Reservoir Computing baseline results\n",
    "\n",
    "We evaluated a minimal Reservoir Computing pipeline on windowed tracking data.\n",
    "\n",
    "Setup:\n",
    "- Window size: 200 frames\n",
    "- Input dimension: 18 features (bodypart coordinates)\n",
    "- Reservoir size: 300 units\n",
    "- Readout: Logistic Regression (class-weighted)\n",
    "- Task: binary classification (chase vs no-chase)\n",
    "\n",
    "Test results:\n",
    "- Accuracy ≈ 0.57\n",
    "- Recall (chase) ≈ 0.55\n",
    "- Precision (chase) ≈ 0.18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed11c96",
   "metadata": {},
   "source": [
    "## Methodological conclusion\n",
    "\n",
    "This experiment validates the applicability of Reservoir Computing to behavioral\n",
    "time series derived from pose estimation data.\n",
    "\n",
    "Key points:\n",
    "- Temporal windowing is essential to transform long continuous recordings into\n",
    "  learnable units compatible with reservoir memory.\n",
    "- A simple ESN architecture with a linear readout is sufficient to detect\n",
    "  behavior-related patterns above chance level.\n",
    "- The pipeline is modular: the same reservoir can be reused with different readouts,\n",
    "  pooling strategies, or labeling schemes.\n",
    "\n",
    "Future work includes scaling to the full dataset, multi-class behavior prediction,\n",
    "and systematic hyperparameter tuning.\n",
    "\n",
    "This experiment is not intended to achieve state-of-the-art performance,\n",
    "but to validate the applicability of Reservoir Computing to behavioral\n",
    "time series data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
