{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d357d180",
   "metadata": {},
   "source": [
    "# MABe – Reservoir Computing Training\n",
    "\n",
    "This notebook loads the preprocessed dataset and trains Reservoir Computing models.\n",
    "It uses the data prepared by `02_dataset_processing_and_scaling.ipynb`.\n",
    "\n",
    "The goal is twofold:\n",
    "1. Detect whether an action occurs in a temporal window (action vs no-action).\n",
    "2. If an action is present, classify the specific behavior (multi-class).\n",
    "\n",
    "The evaluation is intentionally staged to reflect the structure of the problem\n",
    "and to handle extreme class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5f4389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: reservoirpy in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from reservoirpy) (1.15.3)\n",
      "Requirement already satisfied: joblib>=0.14.1 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from reservoirpy) (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.21.1 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from reservoirpy) (2.2.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.10.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\flore\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\flore\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (12.1.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.3.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\flore\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (2.2.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install reservoirpy\n",
    "%pip install matplotlib\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a3d0759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    average_precision_score,\n",
    "    precision_recall_curve,\n",
    ")\n",
    "\n",
    "from reservoirpy.nodes import Reservoir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4d4a2b",
   "metadata": {},
   "source": [
    "## Dataset characteristics\n",
    "\n",
    "Each sample corresponds to a temporal window extracted from pose-tracking data:\n",
    "- Shape: (window_size, features)\n",
    "- window_size = 200 frames\n",
    "- features = body-part coordinates\n",
    "\n",
    "Labels:\n",
    "- A majority of windows correspond to \"no action\".\n",
    "- Action windows are extremely rare (≈ 0.4% of the dataset).\n",
    "- Action classes include: chase, avoid, attack, chaseattack.\n",
    "\n",
    "This extreme imbalance makes accuracy alone a misleading metric and motivates\n",
    "the use of precision/recall-based evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96535338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (16395, 200, 10) float32\n",
      "y: (16395,) int64\n",
      "video_id: (16395,) object\n"
     ]
    }
   ],
   "source": [
    "PROCESSED = Path(\"data/data_processed\")\n",
    "\n",
    "X = np.load(PROCESSED / \"X_windows.npy\")  # (N, T, D)\n",
    "y = np.load(PROCESSED / \"y_windows.npy\")  # (N,)\n",
    "\n",
    "# Important: video_id_windows nécessaire pour split propre par vidéo\n",
    "video_id = np.load(PROCESSED / \"video_id_windows.npy\", allow_pickle=True)  # (N,)\n",
    "\n",
    "# Si tu as aussi mouse_id_windows/category_windows, tu peux charger pareil\n",
    "mouse_id = np.load(PROCESSED / \"mouse_id_windows.npy\", allow_pickle=True)\n",
    "\n",
    "print(\"X:\", X.shape, X.dtype)\n",
    "print(\"y:\", y.shape, y.dtype)\n",
    "print(\"video_id:\", video_id.shape, video_id.dtype)\n",
    "\n",
    "assert X.shape[0] == y.shape[0] == video_id.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34a8769b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global action ratio: 0.9986581274778896\n",
      "Total actions: 16373 over 16395\n"
     ]
    }
   ],
   "source": [
    "NONE_ID = 0  # adapte si ton mapping est différent\n",
    "\n",
    "y_binary = (y != NONE_ID).astype(np.int8)  # 1 si action, 0 si none\n",
    "print(\"Global action ratio:\", y_binary.mean())\n",
    "print(\"Total actions:\", int(y_binary.sum()), \"over\", len(y_binary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4dd59c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (9837, 200, 10) pos: 9824\n",
      "Val:   (3279, 200, 10) pos: 3275\n",
      "Test:  (3279, 200, 10) pos: 3274\n"
     ]
    }
   ],
   "source": [
    "def make_split_with_positives(X, y_binary, video_id=None, test_size=0.2, val_size=0.2, max_tries=200, seed0=42):\n",
    "    \"\"\"\n",
    "    Returns X_train, X_val, X_test, y_train_bin, y_val_bin, y_test_bin, idx_train, idx_val, idx_test\n",
    "    ensuring val and test contain at least 1 positive sample.\n",
    "    (Window-level split; quick and robust for debugging.)\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed0)\n",
    "    n = len(y_binary)\n",
    "    idx_all = np.arange(n)\n",
    "\n",
    "    for t in range(max_tries):\n",
    "        seed = int(rng.randint(0, 10_000_000))\n",
    "\n",
    "        idx_train, idx_tmp, y_train, y_tmp = train_test_split(\n",
    "            idx_all, y_binary, test_size=(test_size + val_size), random_state=seed, stratify=y_binary\n",
    "        )\n",
    "        rel_val = val_size / (test_size + val_size)\n",
    "        idx_val, idx_test, y_val, y_test = train_test_split(\n",
    "            idx_tmp, y_tmp, test_size=(test_size / (test_size + val_size)), random_state=seed + 1, stratify=y_tmp\n",
    "        )\n",
    "\n",
    "        if y_val.sum() > 0 and y_test.sum() > 0:\n",
    "            return idx_train, idx_val, idx_test\n",
    "\n",
    "    raise RuntimeError(\"Could not find a split with positives in both val and test. Need more positives or different strategy.\")\n",
    "\n",
    "idx_train, idx_val, idx_test = make_split_with_positives(X, y_binary, test_size=0.2, val_size=0.2)\n",
    "\n",
    "X_train, X_val, X_test = X[idx_train], X[idx_val], X[idx_test]\n",
    "y_train_bin, y_val_bin, y_test_bin = y_binary[idx_train], y_binary[idx_val], y_binary[idx_test]\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"pos:\", int(y_train_bin.sum()))\n",
    "print(\"Val:  \", X_val.shape,   \"pos:\", int(y_val_bin.sum()))\n",
    "print(\"Test: \", X_test.shape,  \"pos:\", int(y_test_bin.sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "143f3ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_reservoir(units=300, sr=0.9, lr=0.3, input_scaling=0.5, seed=42):\n",
    "    return Reservoir(\n",
    "        units=units,\n",
    "        sr=sr,\n",
    "        lr=lr,\n",
    "        input_scaling=input_scaling,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "def reservoir_transform(reservoir, X_batch, pooling=\"last\"):\n",
    "    \"\"\"\n",
    "    X_batch: (B, T, D)\n",
    "    returns Z: (B, units)\n",
    "    \"\"\"\n",
    "    B = X_batch.shape[0]\n",
    "    Z = np.zeros((B, reservoir.units), dtype=np.float32)\n",
    "\n",
    "    for i in range(B):\n",
    "        reservoir.reset()\n",
    "        states = reservoir.run(X_batch[i])  # (T, units)\n",
    "\n",
    "        if pooling == \"last\":\n",
    "            Z[i] = states[-1]\n",
    "        elif pooling == \"mean\":\n",
    "            Z[i] = states.mean(axis=0)\n",
    "        else:\n",
    "            raise ValueError(\"pooling must be 'last' or 'mean'\")\n",
    "\n",
    "        if (i + 1) % 500 == 0:\n",
    "            print(f\"reservoir_transform {pooling}: {i+1}/{B}\")\n",
    "\n",
    "    return Z\n",
    "\n",
    "def train_and_eval_stageA(X_train_feat, y_train_bin, X_val_feat, y_val_bin, X_test_feat, y_test_bin, name=\"\"):\n",
    "    \"\"\"\n",
    "    Logistic regression + scaling + choose threshold that maximizes F1 on VAL.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "    X_train_s = scaler.fit_transform(X_train_feat)\n",
    "    X_val_s = scaler.transform(X_val_feat)\n",
    "    X_test_s = scaler.transform(X_test_feat)\n",
    "\n",
    "    clf = LogisticRegression(\n",
    "        max_iter=5000,\n",
    "        class_weight=\"balanced\",\n",
    "        solver=\"saga\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    clf.fit(X_train_s, y_train_bin)\n",
    "\n",
    "    # probs\n",
    "    p_val = clf.predict_proba(X_val_s)[:, 1]\n",
    "    p_test = clf.predict_proba(X_test_s)[:, 1]\n",
    "\n",
    "    # PR-AUC on test (threshold-free)\n",
    "    pr_auc = average_precision_score(y_test_bin, p_test)\n",
    "\n",
    "    # threshold sweep on VAL\n",
    "    precision, recall, thresholds = precision_recall_curve(y_val_bin, p_val)\n",
    "    # precision_recall_curve returns thresholds of length (len(precision)-1)\n",
    "    # compute F1 safely for each point\n",
    "    den = precision + recall\n",
    "    f1 = np.where(den > 0, 2 * precision * recall / den, 0.0)\n",
    "\n",
    "    best_idx = int(np.argmax(f1))\n",
    "    best_thresh = 0.5 if best_idx == len(thresholds) else float(thresholds[best_idx])\n",
    "\n",
    "    y_pred_test = (p_test >= best_thresh).astype(np.int8)\n",
    "\n",
    "    cm = confusion_matrix(y_test_bin, y_pred_test, labels=[0, 1])\n",
    "\n",
    "    print(f\"\\nStage A ({name})\")\n",
    "    print(f\"  Test PR-AUC: {pr_auc:.3f}\")\n",
    "    print(f\"  Best threshold (from VAL): {best_thresh:.3f}\")\n",
    "    print(\"  Confusion matrix [ [TN FP] [FN TP] ]:\")\n",
    "    print(cm)\n",
    "    print(\"  Classification report (test):\")\n",
    "    print(classification_report(y_test_bin, y_pred_test, digits=3, zero_division=0))\n",
    "\n",
    "    return clf, scaler, best_thresh, y_pred_test, p_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "baa9a89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stage A (Baseline(flat))\n",
      "  Test PR-AUC: 0.999\n",
      "  Best threshold (from VAL): 0.000\n",
      "  Confusion matrix [ [TN FP] [FN TP] ]:\n",
      "[[   0    5]\n",
      " [   0 3274]]\n",
      "  Classification report (test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000         5\n",
      "           1      0.998     1.000     0.999      3274\n",
      "\n",
      "    accuracy                          0.998      3279\n",
      "   macro avg      0.499     0.500     0.500      3279\n",
      "weighted avg      0.997     0.998     0.998      3279\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Reservoir' object has no attribute 'state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 14\u001b[0m\n\u001b[0;32m      9\u001b[0m clf_A_base, sc_A_base, th_A_base, yhat_A_base, pA_base \u001b[38;5;241m=\u001b[39m train_and_eval_stageA(\n\u001b[0;32m     10\u001b[0m     X_train_flat, y_train_bin, X_val_flat, y_val_bin, X_test_flat, y_test_bin, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseline(flat)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Reservoir last\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m Z_train_last \u001b[38;5;241m=\u001b[39m \u001b[43mreservoir_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreservoir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlast\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m Z_val_last   \u001b[38;5;241m=\u001b[39m reservoir_transform(reservoir, X_val,   pooling\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m Z_test_last  \u001b[38;5;241m=\u001b[39m reservoir_transform(reservoir, X_test,  pooling\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[18], line 19\u001b[0m, in \u001b[0;36mreservoir_transform\u001b[1;34m(reservoir, X_batch, pooling)\u001b[0m\n\u001b[0;32m     16\u001b[0m Z \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((B, reservoir\u001b[38;5;241m.\u001b[39munits), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(B):\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mreservoir\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     states \u001b[38;5;241m=\u001b[39m reservoir\u001b[38;5;241m.\u001b[39mrun(X_batch[i])  \u001b[38;5;66;03m# (T, units)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pooling \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\flore\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\reservoirpy\\node.py:242\u001b[0m, in \u001b[0;36mNode.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m State:\n\u001b[0;32m    236\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Reset all Node state\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;124;03m    dict[str, np.array]: previous state of the Node.\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 242\u001b[0m     previous_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m {key: np\u001b[38;5;241m.\u001b[39mzeros(val\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m previous_state\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Reservoir' object has no attribute 'state'"
     ]
    }
   ],
   "source": [
    "reservoir_params = {'units': 300, 'sr': 0.9, 'lr': 0.3, 'input_scaling': 0.5, 'seed': 42}\n",
    "reservoir = build_reservoir(**reservoir_params)\n",
    "\n",
    "# Baseline features (flatten)\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_val_flat   = X_val.reshape(X_val.shape[0], -1)\n",
    "X_test_flat  = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "clf_A_base, sc_A_base, th_A_base, yhat_A_base, pA_base = train_and_eval_stageA(\n",
    "    X_train_flat, y_train_bin, X_val_flat, y_val_bin, X_test_flat, y_test_bin, name=\"Baseline(flat)\"\n",
    ")\n",
    "\n",
    "# Reservoir last\n",
    "Z_train_last = reservoir_transform(reservoir, X_train, pooling=\"last\")\n",
    "Z_val_last   = reservoir_transform(reservoir, X_val,   pooling=\"last\")\n",
    "Z_test_last  = reservoir_transform(reservoir, X_test,  pooling=\"last\")\n",
    "\n",
    "clf_A_last, sc_A_last, th_A_last, yhat_A_last, pA_last = train_and_eval_stageA(\n",
    "    Z_train_last, y_train_bin, Z_val_last, y_val_bin, Z_test_last, y_test_bin, name=\"Reservoir(last)\"\n",
    ")\n",
    "\n",
    "# Reservoir mean\n",
    "Z_train_mean = reservoir_transform(reservoir, X_train, pooling=\"mean\")\n",
    "Z_val_mean   = reservoir_transform(reservoir, X_val,   pooling=\"mean\")\n",
    "Z_test_mean  = reservoir_transform(reservoir, X_test,  pooling=\"mean\")\n",
    "\n",
    "clf_A_mean, sc_A_mean, th_A_mean, yhat_A_mean, pA_mean = train_and_eval_stageA(\n",
    "    Z_train_mean, y_train_bin, Z_val_mean, y_val_bin, Z_test_mean, y_test_bin, name=\"Reservoir(mean)\"\n",
    ")\n",
    "\n",
    "print(\"\\nAction detection counts in TEST:\")\n",
    "print(\"  True actions:\", int(y_test_bin.sum()))\n",
    "print(\"  Pred actions baseline:\", int(yhat_A_base.sum()))\n",
    "print(\"  Pred actions res-last:\", int(yhat_A_last.sum()))\n",
    "print(\"  Pred actions res-mean:\", int(yhat_A_mean.sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db66f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage B ground truth: only true action windows\n",
    "train_action_mask = (y[idx_train] != NONE_ID)\n",
    "val_action_mask   = (y[idx_val]   != NONE_ID)\n",
    "test_action_mask  = (y[idx_test]  != NONE_ID)\n",
    "\n",
    "X_train_action = X_train[train_action_mask]\n",
    "X_val_action   = X_val[val_action_mask]\n",
    "X_test_action  = X_test[test_action_mask]\n",
    "\n",
    "y_train_action = y[idx_train][train_action_mask]  # labels multi-class but without none\n",
    "y_val_action   = y[idx_val][val_action_mask]\n",
    "y_test_action  = y[idx_test][test_action_mask]\n",
    "\n",
    "print(\"Stage B datasets (true actions only):\")\n",
    "print(\"  Train:\", X_train_action.shape, \"labels:\", y_train_action.shape)\n",
    "print(\"  Val:  \", X_val_action.shape,   \"labels:\", y_val_action.shape)\n",
    "print(\"  Test: \", X_test_action.shape,  \"labels:\", y_test_action.shape)\n",
    "\n",
    "if len(y_test_action) == 0:\n",
    "    print(\"\\nWARNING: No true action windows in TEST. Stage B cannot be evaluated on this split.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242b5c53",
   "metadata": {},
   "source": [
    "## Reservoir Computing Model\n",
    "\n",
    "Define and train the reservoir model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a789df88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage A: Baseline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flore\\AppData\\Local\\Temp\\ipykernel_32192\\2207658381.py:33: RuntimeWarning: invalid value encountered in divide\n",
      "  f1_scores = 2 * (precision * recall) / (precision + recall)\n",
      "c:\\Users\\flore\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stage A (Baseline):\n",
      "  PR-AUC: 0.026\n",
      "  Threshold: 0.609\n",
      "  Precision: 0.000, Recall: 0.000, F1: 0.000\n",
      "  Confusion Matrix:\n",
      "[[5879   61]\n",
      " [   0    0]]\n",
      "  Threshold Sweep (sample):\n",
      "    0.00: P=0.002, R=1.000, F1=0.004\n",
      "    0.03: P=0.002, R=1.000, F1=0.004\n",
      "    0.05: P=0.002, R=0.833, F1=0.004\n",
      "    0.08: P=0.002, R=0.833, F1=0.005\n",
      "    0.12: P=0.003, R=0.833, F1=0.005\n",
      "    0.15: P=0.003, R=0.833, F1=0.007\n",
      "    0.18: P=0.004, R=0.833, F1=0.008\n",
      "    0.21: P=0.005, R=0.833, F1=0.011\n",
      "    0.25: P=0.007, R=0.667, F1=0.013\n",
      "    0.30: P=0.013, R=0.667, F1=0.025\n",
      "    1.00: P=0.000, R=0.000, F1=0.000\n",
      "Stage A: Reservoir (last pooling)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flore\\AppData\\Local\\Temp\\ipykernel_32192\\2207658381.py:33: RuntimeWarning: invalid value encountered in divide\n",
      "  f1_scores = 2 * (precision * recall) / (precision + recall)\n",
      "c:\\Users\\flore\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stage A (Reservoir Last):\n",
      "  PR-AUC: 0.002\n",
      "  Threshold: 0.346\n",
      "  Precision: 0.000, Recall: 0.000, F1: 0.000\n",
      "  Confusion Matrix:\n",
      "[[3033 2907]\n",
      " [   0    0]]\n",
      "  Threshold Sweep (sample):\n",
      "    0.00: P=0.002, R=1.000, F1=0.004\n",
      "    0.04: P=0.002, R=1.000, F1=0.004\n",
      "    0.08: P=0.002, R=0.833, F1=0.004\n",
      "    0.21: P=0.002, R=0.833, F1=0.005\n",
      "    0.33: P=0.003, R=0.833, F1=0.005\n",
      "    0.42: P=0.001, R=0.333, F1=0.003\n",
      "    0.48: P=0.002, R=0.333, F1=0.003\n",
      "    0.57: P=0.002, R=0.333, F1=0.004\n",
      "    0.65: P=0.002, R=0.167, F1=0.003\n",
      "    0.72: P=0.000, R=0.000, F1=0.000\n",
      "    0.96: P=0.000, R=0.000, F1=0.000\n",
      "Stage A: Reservoir (mean pooling)\n",
      "\n",
      "Stage A (Reservoir Mean):\n",
      "  PR-AUC: 0.002\n",
      "  Threshold: 0.214\n",
      "  Precision: 0.000, Recall: 0.000, F1: 0.000\n",
      "  Confusion Matrix:\n",
      "[[2507 3433]\n",
      " [   0    0]]\n",
      "  Threshold Sweep (sample):\n",
      "    0.00: P=0.002, R=1.000, F1=0.004\n",
      "    0.01: P=0.002, R=1.000, F1=0.004\n",
      "    0.04: P=0.002, R=1.000, F1=0.005\n",
      "    0.12: P=0.003, R=1.000, F1=0.006\n",
      "    0.27: P=0.003, R=0.833, F1=0.005\n",
      "    0.40: P=0.003, R=0.667, F1=0.005\n",
      "    0.49: P=0.002, R=0.500, F1=0.005\n",
      "    0.58: P=0.002, R=0.333, F1=0.004\n",
      "    0.65: P=0.002, R=0.167, F1=0.003\n",
      "    0.73: P=0.000, R=0.000, F1=0.000\n",
      "    1.00: P=0.000, R=0.000, F1=0.000\n",
      "\n",
      "Action detection in test:\n",
      "  True actions: 0\n",
      "  Detected (Baseline): 61\n",
      "  Detected (Res Last): 2907\n",
      "  Detected (Res Mean): 3433\n",
      "Stage B: Baseline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\flore\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\flore\\AppData\\Local\\Temp\\ipykernel_32192\\2207658381.py:33: RuntimeWarning: invalid value encountered in divide\n",
      "  f1_scores = 2 * (precision * recall) / (precision + recall)\n",
      "c:\\Users\\flore\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 0 into shape (0,newaxis)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 54\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStage B: Baseline\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     53\u001b[0m X_train_action_flat \u001b[38;5;241m=\u001b[39m X_train_action\u001b[38;5;241m.\u001b[39mreshape(X_train_action\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 54\u001b[0m X_test_action_flat \u001b[38;5;241m=\u001b[39m \u001b[43mX_test_action\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_action\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m clf_B_baseline \u001b[38;5;241m=\u001b[39m train_and_eval_stageB(\n\u001b[0;32m     56\u001b[0m     X_train_action_flat, y_train_action, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, X_test_action_flat, y_test_action, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseline\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     57\u001b[0m )\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Stage B: Reservoir (last)\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 0 into shape (0,newaxis)"
     ]
    }
   ],
   "source": [
    "def train_and_eval_stageB(X_train_feat, y_train_mc, X_test_feat, y_test_mc, name=\"\"):\n",
    "    scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "    X_train_s = scaler.fit_transform(X_train_feat)\n",
    "    X_test_s = scaler.transform(X_test_feat)\n",
    "\n",
    "    clf = LogisticRegression(\n",
    "        max_iter=5000,\n",
    "        class_weight=\"balanced\",\n",
    "        solver=\"saga\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        multi_class=\"multinomial\"\n",
    "    )\n",
    "    clf.fit(X_train_s, y_train_mc)\n",
    "    y_pred = clf.predict(X_test_s)\n",
    "\n",
    "    print(f\"\\nStage B ({name})\")\n",
    "    print(\"  Classification report (test, true action windows):\")\n",
    "    print(classification_report(y_test_mc, y_pred, digits=3, zero_division=0))\n",
    "    print(\"  Confusion matrix:\")\n",
    "    print(confusion_matrix(y_test_mc, y_pred))\n",
    "\n",
    "    return clf, scaler, y_pred\n",
    "\n",
    "if len(y_test_action) == 0:\n",
    "    print(\"Skipping Stage B due to empty test_action set.\")\n",
    "else:\n",
    "    # Baseline: flatten\n",
    "    X_train_action_flat = X_train_action.reshape(X_train_action.shape[0], -1)\n",
    "    X_test_action_flat  = X_test_action.reshape(X_test_action.shape[0], -1)\n",
    "    clf_B_base, sc_B_base, yhat_B_base = train_and_eval_stageB(\n",
    "        X_train_action_flat, y_train_action, X_test_action_flat, y_test_action, name=\"Baseline(flat)\"\n",
    "    )\n",
    "\n",
    "    # Reservoir last\n",
    "    Z_train_action_last = reservoir_transform(reservoir, X_train_action, pooling=\"last\")\n",
    "    Z_test_action_last  = reservoir_transform(reservoir, X_test_action,  pooling=\"last\")\n",
    "    clf_B_last, sc_B_last, yhat_B_last = train_and_eval_stageB(\n",
    "        Z_train_action_last, y_train_action, Z_test_action_last, y_test_action, name=\"Reservoir(last)\"\n",
    "    )\n",
    "\n",
    "    # Reservoir mean\n",
    "    Z_train_action_mean = reservoir_transform(reservoir, X_train_action, pooling=\"mean\")\n",
    "    Z_test_action_mean  = reservoir_transform(reservoir, X_test_action,  pooling=\"mean\")\n",
    "    clf_B_mean, sc_B_mean, yhat_B_mean = train_and_eval_stageB(\n",
    "        Z_train_action_mean, y_train_action, Z_test_action_mean, y_test_action, name=\"Reservoir(mean)\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
