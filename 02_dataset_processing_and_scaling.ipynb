{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8cd9b7e",
   "metadata": {},
   "source": [
    "# MABe – Dataset Processing and Scaling\n",
    "\n",
    "This notebook processes the entire MABe dataset for Reservoir Computing training.\n",
    "It loads all tracking files, extracts common features, and creates windowed datasets.\n",
    "\n",
    "**Prerequisites:** Run `01_exploration.ipynb` first to understand the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bc101e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (22.0.0)\n",
      "Requirement already satisfied: fastparquet in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2025.12.0)\n",
      "Requirement already satisfied: reservoirpy in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fastparquet) (2.2.6)\n",
      "Requirement already satisfied: pandas>=1.5.0 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fastparquet) (2.3.3)\n",
      "Requirement already satisfied: cramjam>=2.3 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fastparquet) (2.11.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\flore\\appdata\\roaming\\python\\python310\\site-packages (from fastparquet) (25.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fastparquet) (2026.1.0)\n",
      "Requirement already satisfied: joblib>=0.14.1 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from reservoirpy) (1.5.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from reservoirpy) (1.15.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\flore\\appdata\\roaming\\python\\python310\\site-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\flore\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\flore\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pyarrow fastparquet\n",
    "%pip install reservoirpy\n",
    "%pip install matplotlib\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d53a8c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d886193",
   "metadata": {},
   "source": [
    "## Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63a0856d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directories:\n",
      "  Tracking: data\\data_raw\\train_tracking\n",
      "  Annotations: data\\data_raw\\train_annotation\n",
      "  Processed: data\\data_processed\n"
     ]
    }
   ],
   "source": [
    "TRACK_ROOT = Path(\"data/data_raw/train_tracking\")\n",
    "ANNOT_ROOT = Path(\"data/data_raw/train_annotation\")\n",
    "PROCESSED_ROOT = Path(\"data/data_processed\")\n",
    "PROCESSED_ROOT.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Data directories:\")\n",
    "print(f\"  Tracking: {TRACK_ROOT}\")\n",
    "print(f\"  Annotations: {ANNOT_ROOT}\")\n",
    "print(f\"  Processed: {PROCESSED_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bd9cc3",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab357baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotation(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Load annotation file based on extension.\"\"\"\n",
    "    suffix = path.suffix.lower()\n",
    "    if suffix == \".parquet\":\n",
    "        return pd.read_parquet(path)\n",
    "    if suffix == \".csv\":\n",
    "        return pd.read_csv(path)\n",
    "    if suffix in [\".tsv\", \".txt\"]:\n",
    "        return pd.read_csv(path, sep=\"\\t\")\n",
    "    raise ValueError(f\"Unsupported annotation file type: {path}\")\n",
    "\n",
    "def find_common_bodyparts(categories, max_files_per_category=10):\n",
    "    \"\"\"Find bodyparts common to all files in the given categories.\"\"\"\n",
    "    all_bodyparts = None\n",
    "    for category in categories:\n",
    "        category_path = TRACK_ROOT / category\n",
    "        tracking_files = list(category_path.glob(\"*.parquet\"))[:max_files_per_category]\n",
    "        \n",
    "        for tracking_path in tracking_files:\n",
    "            df = pd.read_parquet(tracking_path)\n",
    "            df_mouse = df[df[\"mouse_id\"] == 1]\n",
    "            bodyparts = set(df_mouse[\"bodypart\"].unique())\n",
    "            if all_bodyparts is None:\n",
    "                all_bodyparts = bodyparts\n",
    "            else:\n",
    "                all_bodyparts = all_bodyparts.intersection(bodyparts)\n",
    "    \n",
    "    # Remove bad bodyparts\n",
    "    bad_bodyparts = {\"neck\"}\n",
    "    all_bodyparts = all_bodyparts - bad_bodyparts\n",
    "    return all_bodyparts\n",
    "\n",
    "def process_tracking_file(tracking_path: Path, mouse_id: int = 1, bad_bodyparts: list = [\"neck\"], common_bodyparts: set = None):\n",
    "    \"\"\"Process a single tracking file into X_final and return metadata.\"\"\"\n",
    "    # Load tracking data\n",
    "    df = pd.read_parquet(tracking_path)\n",
    "    \n",
    "    # Filter to specific mouse\n",
    "    df_mouse = df[df[\"mouse_id\"] == mouse_id]\n",
    "    \n",
    "    # Convert to wide format\n",
    "    df_wide = (\n",
    "        df_mouse\n",
    "        .pivot(index=\"video_frame\", columns=\"bodypart\", values=[\"x\", \"y\"])\n",
    "        .sort_index()\n",
    "    )\n",
    "    df_wide.columns = [f\"{coord}_{part}\" for coord, part in df_wide.columns]\n",
    "    \n",
    "    # Filter to common bodyparts if specified\n",
    "    if common_bodyparts is not None:\n",
    "        cols_to_keep = []\n",
    "        for col in df_wide.columns:\n",
    "            # col is like \"x_bodypart\" or \"y_bodypart\"\n",
    "            parts = col.split('_', 1)\n",
    "            if len(parts) == 2:\n",
    "                coord, bodypart = parts\n",
    "                if bodypart in common_bodyparts:\n",
    "                    cols_to_keep.append(col)\n",
    "        df_wide = df_wide[cols_to_keep]\n",
    "    \n",
    "    # Remove bad bodyparts\n",
    "    cols_to_drop = [\n",
    "        col for col in df_wide.columns\n",
    "        if any(bp in col for bp in bad_bodyparts)\n",
    "    ]\n",
    "    df_clean = df_wide.drop(columns=cols_to_drop)\n",
    "    \n",
    "    # Interpolate NaNs\n",
    "    df_interp = df_clean.interpolate(method=\"linear\").ffill().bfill()\n",
    "    \n",
    "    # Convert to numpy\n",
    "    X_final = df_interp.to_numpy(dtype=np.float32)\n",
    "    \n",
    "    return X_final, df_interp.index.to_numpy()  # frames\n",
    "\n",
    "def process_annotation_file(tracking_path: Path, frames: np.ndarray, mouse_id: int = 1, action_name: str = \"chase\"):\n",
    "    \"\"\"Create y array from annotation file matching the tracking file.\"\"\"\n",
    "    file_id = tracking_path.stem\n",
    "    category = tracking_path.parent.name\n",
    "    annot_path = ANNOT_ROOT / category / f\"{file_id}.parquet\"\n",
    "    \n",
    "    if not annot_path.exists():\n",
    "        print(f\"Warning: No annotation for {tracking_path}\")\n",
    "        return np.zeros(len(frames), dtype=np.int8)\n",
    "    \n",
    "    ann = load_annotation(annot_path)\n",
    "    ann_sel = ann[(ann[\"agent_id\"] == mouse_id) & (ann[\"action\"] == action_name)]\n",
    "    \n",
    "    y = np.zeros(len(frames), dtype=np.int8)\n",
    "    for start, stop in ann_sel[[\"start_frame\", \"stop_frame\"]].itertuples(index=False, name=None):\n",
    "        mask = (frames >= start) & (frames <= stop)\n",
    "        y[mask] = 1\n",
    "    \n",
    "    return y\n",
    "\n",
    "def create_windows(X, y, window_size=200, step=200):\n",
    "    \"\"\"Create windowed dataset from time series X and y.\"\"\"\n",
    "    Xw, yw = [], []\n",
    "    T = X.shape[0]\n",
    "    for start in range(0, T - window_size + 1, step):\n",
    "        end = start + window_size\n",
    "        Xw.append(X[start:end])\n",
    "        yw.append(1 if y[start:end].any() else 0)\n",
    "    return np.stack(Xw), np.array(yw, dtype=np.int8)\n",
    "\n",
    "# Multi-class classification setup\n",
    "actions = [\"chase\", \"avoid\", \"attack\", \"chaseattack\"]\n",
    "classes = actions + [\"none\"]  # Add \"none\" class for no action\n",
    "class_to_id = {cls: i for i, cls in enumerate(classes)}\n",
    "id_to_class = {i: cls for i, cls in enumerate(classes)}\n",
    "priority_order = [\"chaseattack\", \"attack\", \"chase\", \"avoid\"]  # Highest priority first\n",
    "\n",
    "def process_annotation_multiclass(tracking_path: Path, mouse_id: int = 1):\n",
    "    \"\"\"Load annotation file and return filtered segments for the mouse.\"\"\"\n",
    "    file_id = tracking_path.stem\n",
    "    category = tracking_path.parent.name\n",
    "    annot_path = ANNOT_ROOT / category / f\"{file_id}.parquet\"\n",
    "    \n",
    "    if not annot_path.exists():\n",
    "        print(f\"Warning: No annotation for {tracking_path}\")\n",
    "        return pd.DataFrame()  # Return empty DataFrame\n",
    "    \n",
    "    ann = load_annotation(annot_path)\n",
    "    ann_sel = ann[ann[\"agent_id\"] == mouse_id].copy()\n",
    "    return ann_sel\n",
    "\n",
    "def create_windows_multiclass(X, ann_segments, frames, window_size=200, step=200):\n",
    "    \"\"\"Create windowed dataset with multi-class labels from annotation segments.\"\"\"\n",
    "    Xw, yw, window_starts, window_ends = [], [], [], []\n",
    "    T = X.shape[0]\n",
    "    \n",
    "    for start in range(0, T - window_size + 1, step):\n",
    "        end = start + window_size\n",
    "        \n",
    "        # Get frame range for this window\n",
    "        window_start_frame = frames[start]\n",
    "        window_end_frame = frames[end-1]\n",
    "        \n",
    "        # Find actions that overlap with this window\n",
    "        overlapping_actions = set()\n",
    "        for _, segment in ann_segments.iterrows():\n",
    "            seg_start = segment[\"start_frame\"]\n",
    "            seg_end = segment[\"stop_frame\"]\n",
    "            action = segment[\"action\"]\n",
    "            \n",
    "            # Check for overlap: segments overlap if seg_start < window_end and seg_end > window_start\n",
    "            if seg_start < window_end_frame and seg_end > window_start_frame:\n",
    "                overlapping_actions.add(action)\n",
    "        \n",
    "        # Determine label based on priority\n",
    "        if not overlapping_actions:\n",
    "            label = \"none\"\n",
    "        else:\n",
    "            # Find highest priority action\n",
    "            for action in priority_order:\n",
    "                if action in overlapping_actions:\n",
    "                    label = action\n",
    "                    break\n",
    "        \n",
    "        # Convert to class ID\n",
    "        y_label = class_to_id[label]\n",
    "        \n",
    "        # Store window\n",
    "        Xw.append(X[start:end])\n",
    "        yw.append(y_label)\n",
    "        window_starts.append(window_start_frame)\n",
    "        window_ends.append(window_end_frame)\n",
    "    \n",
    "    return (np.stack(Xw), \n",
    "            np.array(yw, dtype=np.int64), \n",
    "            np.array(window_starts, dtype=np.int64), \n",
    "            np.array(window_ends, dtype=np.int64))\n",
    "\n",
    "# Multi-class classification setup\n",
    "actions = [\"chase\", \"avoid\", \"attack\", \"chaseattack\"]\n",
    "classes = actions + [\"none\"]  # Add \"none\" class for no action\n",
    "class_to_id = {cls: i for i, cls in enumerate(classes)}\n",
    "id_to_class = {i: cls for i, cls in enumerate(classes)}\n",
    "priority_order = [\"chaseattack\", \"attack\", \"chase\", \"avoid\"]  # Highest priority first\n",
    "\n",
    "def process_annotation_multiclass(tracking_path: Path, mouse_id: int = 1):\n",
    "    \"\"\"Load annotation file and return filtered segments for the mouse.\"\"\"\n",
    "    file_id = tracking_path.stem\n",
    "    category = tracking_path.parent.name\n",
    "    annot_path = ANNOT_ROOT / category / f\"{file_id}.parquet\"\n",
    "    \n",
    "    if not annot_path.exists():\n",
    "        print(f\"Warning: No annotation for {tracking_path}\")\n",
    "        return pd.DataFrame()  # Return empty DataFrame\n",
    "    \n",
    "    ann = load_annotation(annot_path)\n",
    "    ann_sel = ann[ann[\"agent_id\"] == mouse_id].copy()\n",
    "    return ann_sel\n",
    "\n",
    "def create_windows_multiclass(X, ann_segments, frames, window_size=200, step=200):\n",
    "    \"\"\"Create windowed dataset with multi-class labels from annotation segments.\"\"\"\n",
    "    Xw, yw, window_starts, window_ends = [], [], [], []\n",
    "    T = X.shape[0]\n",
    "    \n",
    "    for start in range(0, T - window_size + 1, step):\n",
    "        end = start + window_size\n",
    "        \n",
    "        # Get frame range for this window\n",
    "        window_start_frame = frames[start]\n",
    "        window_end_frame = frames[end-1]\n",
    "        \n",
    "        # Find actions that overlap with this window\n",
    "        overlapping_actions = set()\n",
    "        for _, segment in ann_segments.iterrows():\n",
    "            seg_start = segment[\"start_frame\"]\n",
    "            seg_end = segment[\"stop_frame\"]\n",
    "            action = segment[\"action\"]\n",
    "            \n",
    "            # Check for overlap: segments overlap if seg_start < window_end and seg_end > window_start\n",
    "            if seg_start < window_end_frame and seg_end > window_start_frame:\n",
    "                overlapping_actions.add(action)\n",
    "        \n",
    "        # Determine label based on priority\n",
    "        if not overlapping_actions:\n",
    "            label = \"none\"\n",
    "        else:\n",
    "            # Find highest priority action\n",
    "            for action in priority_order:\n",
    "                if action in overlapping_actions:\n",
    "                    label = action\n",
    "                    break\n",
    "        \n",
    "        # Convert to class ID\n",
    "        y_label = class_to_id[label]\n",
    "        \n",
    "        # Store window\n",
    "        Xw.append(X[start:end])\n",
    "        yw.append(y_label)\n",
    "        window_starts.append(window_start_frame)\n",
    "        window_ends.append(window_end_frame)\n",
    "    \n",
    "    return (np.stack(Xw), \n",
    "            np.array(yw, dtype=np.int64), \n",
    "            np.array(window_starts, dtype=np.int64), \n",
    "            np.array(window_ends, dtype=np.int64))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf4b2ce",
   "metadata": {},
   "source": [
    "## Batch Processing Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9210cc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will process 2 categories: ['AdaptableSnail', 'BoisterousParrot']\n",
      "Parameters: mouse_id=1, action='chase', window_size=200\n"
     ]
    }
   ],
   "source": [
    "# Processing parameters\n",
    "mouse_id = 1\n",
    "action_name = \"chase\"\n",
    "window_size = 200\n",
    "step = 200\n",
    "bad_bodyparts = [\"neck\"]\n",
    "\n",
    "# Categories to process (uncomment for all)\n",
    "# categories = [d.name for d in TRACK_ROOT.iterdir() if d.is_dir()]\n",
    "categories = [\"AdaptableSnail\", \"BoisterousParrot\"]  # Test with 2 categories\n",
    "\n",
    "print(f\"Will process {len(categories)} categories: {categories}\")\n",
    "print(f\"Parameters: mouse_id={mouse_id}, action='{action_name}', window_size={window_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b4bbe0",
   "metadata": {},
   "source": [
    "## Find Common Bodyparts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aca06dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding common bodyparts across files...\n",
      "Common bodyparts (5): ['body_center', 'ear_left', 'ear_right', 'nose', 'tail_base']\n",
      "Total features per mouse: 10 (x,y coordinates)\n"
     ]
    }
   ],
   "source": [
    "print(\"Finding common bodyparts across files...\")\n",
    "common_bodyparts = find_common_bodyparts(categories, max_files_per_category=10)\n",
    "print(f\"Common bodyparts ({len(common_bodyparts)}): {sorted(common_bodyparts)}\")\n",
    "print(f\"Total features per mouse: {len(common_bodyparts) * 2} (x,y coordinates)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab8d48b",
   "metadata": {},
   "source": [
    "## Process All Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0557ed17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing category: AdaptableSnail\n",
      "  Processing: 1212811043.parquet\n",
      "  Processing: 1260392287.parquet\n",
      "  Processing: 1351098077.parquet\n",
      "  Processing: 1408652858.parquet\n",
      "  Processing: 143861384.parquet\n",
      "\n",
      "Processing category: BoisterousParrot\n",
      "  Processing: 1059582964.parquet\n",
      "  Processing: 1184291605.parquet\n",
      "  Processing: 1201849558.parquet\n",
      "  Processing: 1459695188.parquet\n",
      "  Processing: 1985626297.parquet\n",
      "\n",
      "=== DATASET SUMMARY ===\n",
      "Total windows: 16,395\n",
      "Window shape: (200, 10) (timesteps × features)\n",
      "Classes: ['chase', 'avoid', 'attack', 'chaseattack', 'none']\n",
      "  chase: 22 (0.001)\n",
      "  avoid: 52 (0.003)\n",
      "  attack: 111 (0.007)\n",
      "  chaseattack: 27 (0.002)\n",
      "  none: 16,183 (0.987)\n",
      "Files processed: 10\n",
      "\n",
      "✅ Data saved to data\\data_processed\n",
      "✅ Class mappings saved to class_mappings.json\n",
      "Ready for training with 03_training.ipynb\n"
     ]
    }
   ],
   "source": [
    "all_X_windows = []\n",
    "all_y_windows = []\n",
    "file_info = []\n",
    "\n",
    "# Initialize metadata lists\n",
    "video_id_windows = []\n",
    "category_windows = []\n",
    "mouse_id_windows = []\n",
    "window_start_frame_windows = []\n",
    "\n",
    "for category in categories:\n",
    "    print(f\"\\nProcessing category: {category}\")\n",
    "    category_path = TRACK_ROOT / category\n",
    "    tracking_files = list(category_path.glob(\"*.parquet\"))\n",
    "    \n",
    "    # Limit for testing - remove for full processing\n",
    "    tracking_files = tracking_files[:5]  # First 5 files per category\n",
    "    \n",
    "    for tracking_path in tracking_files:\n",
    "        print(f\"  Processing: {tracking_path.name}\")\n",
    "        \n",
    "        try:\n",
    "            # Process tracking\n",
    "            X_final, frames = process_tracking_file(tracking_path, mouse_id, bad_bodyparts, common_bodyparts)\n",
    "            \n",
    "            # Process annotation (multi-class)\n",
    "            ann_segments = process_annotation_multiclass(tracking_path, mouse_id)\n",
    "            \n",
    "            # Create windows (multi-class)\n",
    "            X_windows, y_windows, window_starts, window_ends = create_windows_multiclass(\n",
    "                X_final, ann_segments, frames, window_size, step)\n",
    "            \n",
    "            if len(X_windows) > 0:\n",
    "                all_X_windows.append(X_windows)\n",
    "                all_y_windows.append(y_windows)\n",
    "                file_info.append({\n",
    "                    'category': category,\n",
    "                    'file': tracking_path.name,\n",
    "                    'n_windows': len(X_windows),\n",
    "                    'class_counts': np.bincount(y_windows, minlength=len(classes)),\n",
    "                    'n_features': X_final.shape[1]\n",
    "                })\n",
    "                \n",
    "                # Collect metadata for each window\n",
    "                for i in range(len(X_windows)):\n",
    "                    video_id_windows.append(tracking_path.stem)\n",
    "                    category_windows.append(category)\n",
    "                    mouse_id_windows.append(mouse_id)\n",
    "                    window_start_frame_windows.append(window_starts[i])\n",
    "            else:\n",
    "                print(f\"    Warning: No windows created for {tracking_path.name}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"    Error processing {tracking_path.name}: {e}\")\n",
    "            continue\n",
    "\n",
    "# Combine all data\n",
    "if all_X_windows:\n",
    "    X_all = np.concatenate(all_X_windows, axis=0)\n",
    "    y_all = np.concatenate(all_y_windows, axis=0)\n",
    "    \n",
    "    print(\"\\n=== DATASET SUMMARY ===\")\n",
    "    print(f\"Total windows: {len(X_all):,}\")\n",
    "    print(f\"Window shape: {X_all.shape[1:]} (timesteps × features)\")\n",
    "    print(f\"Classes: {classes}\")\n",
    "    class_counts = np.bincount(y_all, minlength=len(classes))\n",
    "    for i, (cls, count) in enumerate(zip(classes, class_counts)):\n",
    "        ratio = count / len(y_all)\n",
    "        print(f\"  {cls}: {count:,} ({ratio:.3f})\")\n",
    "    print(f\"Files processed: {len(file_info)}\")\n",
    "    \n",
    "    # Save processed data\n",
    "    np.save(PROCESSED_ROOT / \"X_windows.npy\", X_all)\n",
    "    np.save(PROCESSED_ROOT / \"y_windows.npy\", y_all)\n",
    "    \n",
    "    # Save metadata arrays\n",
    "    np.save(PROCESSED_ROOT / \"video_id_windows.npy\", np.array(video_id_windows, dtype=object))\n",
    "    np.save(PROCESSED_ROOT / \"category_windows.npy\", np.array(category_windows, dtype=object))\n",
    "    np.save(PROCESSED_ROOT / \"mouse_id_windows.npy\", np.array(mouse_id_windows, dtype=np.int8))\n",
    "    np.save(PROCESSED_ROOT / \"window_start_frame_windows.npy\", np.array(window_start_frame_windows, dtype=np.int32))\n",
    "    \n",
    "    # Save class mappings\n",
    "    class_mappings = {\n",
    "        'classes': classes,\n",
    "        'class_to_id': class_to_id,\n",
    "        'id_to_class': id_to_class,\n",
    "        'priority_order': priority_order\n",
    "    }\n",
    "    with open(PROCESSED_ROOT / \"class_mappings.json\", 'w') as f:\n",
    "        json.dump(class_mappings, f, indent=2)\n",
    "    \n",
    "    with open(PROCESSED_ROOT / \"file_info.pkl\", 'wb') as f:\n",
    "        pickle.dump(file_info, f)\n",
    "    \n",
    "    print(f\"\\n✅ Data saved to {PROCESSED_ROOT}\")\n",
    "    print(\"✅ Class mappings saved to class_mappings.json\")\n",
    "    print(\"Ready for training with 03_training.ipynb\")\n",
    "else:\n",
    "    print(\"❌ No data processed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff99b3bd",
   "metadata": {},
   "source": [
    "## Processing Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "060af397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File breakdown:\n",
      "  AdaptableSnail/1212811043.parquet: 367 windows [chase:14, avoid:26, attack:68, chaseattack:27, none:232]\n",
      "  AdaptableSnail/1260392287.parquet: 269 windows [avoid:11, attack:1, none:257]\n",
      "  AdaptableSnail/1351098077.parquet: 400 windows [avoid:3, attack:2, none:395]\n",
      "  AdaptableSnail/1408652858.parquet: 92 windows [avoid:6, none:86]\n",
      "  AdaptableSnail/143861384.parquet: 417 windows [chase:8, avoid:6, attack:40, none:363]\n",
      "  BoisterousParrot/1059582964.parquet: 2970 windows [none:2970]\n",
      "  BoisterousParrot/1184291605.parquet: 2970 windows [none:2970]\n",
      "  BoisterousParrot/1201849558.parquet: 2970 windows [none:2970]\n",
      "  BoisterousParrot/1459695188.parquet: 2970 windows [none:2970]\n",
      "  BoisterousParrot/1985626297.parquet: 2970 windows [none:2970]\n",
      "\n",
      "Total: 16395 windows from 10 files\n"
     ]
    }
   ],
   "source": [
    "if all_X_windows:\n",
    "    print(\"File breakdown:\")\n",
    "    for info in file_info:\n",
    "        class_counts_str = \", \".join([f\"{classes[i]}:{count}\" for i, count in enumerate(info['class_counts']) if count > 0])\n",
    "        print(f\"  {info['category']}/{info['file']}: {info['n_windows']} windows [{class_counts_str}]\")\n",
    "    \n",
    "    print(f\"\\nTotal: {sum(info['n_windows'] for info in file_info)} windows from {len(file_info)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96571e2",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e919c8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MULTI-CLASS DATASET SANITY CHECK ===\n",
      "Class counts: {'chase': np.int64(22), 'avoid': np.int64(52), 'attack': np.int64(111), 'chaseattack': np.int64(27), 'none': np.int64(16183)}\n",
      "Class ratios: {'chase': np.float64(0.0013418725221103994), 'avoid': np.float64(0.0031716986886245807), 'attack': np.float64(0.00677035681610247), 'chaseattack': np.float64(0.001646843549862763), 'none': np.float64(0.9870692284232998)}\n",
      "\n",
      "Examples of windows with actions (showing first 5):\n",
      "  Window 0: class 'chase'\n",
      "  Window 1: class 'chase'\n",
      "  Window 4: class 'chase'\n",
      "  Window 5: class 'chase'\n",
      "  Window 7: class 'chase'\n",
      "\n",
      "Total windows: 16395\n",
      "Windows with actions: 212 (0.013)\n"
     ]
    }
   ],
   "source": [
    "# Sanity check for multi-class dataset\n",
    "if 'y_all' in locals() and len(y_all) > 0:\n",
    "    print(\"=== MULTI-CLASS DATASET SANITY CHECK ===\")\n",
    "    \n",
    "    # Class distribution\n",
    "    class_counts = np.bincount(y_all, minlength=len(classes))\n",
    "    print(f\"Class counts: {dict(zip(classes, class_counts))}\")\n",
    "    print(f\"Class ratios: {dict(zip(classes, class_counts / len(y_all)))}\")\n",
    "    \n",
    "    # Show some examples of non-\"none\" windows\n",
    "    none_id = class_to_id[\"none\"]\n",
    "    non_none_indices = np.where(y_all != none_id)[0]\n",
    "    \n",
    "    if len(non_none_indices) > 0:\n",
    "        print(f\"\\nExamples of windows with actions (showing first 5):\")\n",
    "        for i in non_none_indices[:5]:\n",
    "            class_name = id_to_class[y_all[i]]\n",
    "            print(f\"  Window {i}: class '{class_name}'\")\n",
    "    else:\n",
    "        print(\"\\nNo windows with actions found in this dataset!\")\n",
    "    \n",
    "    print(f\"\\nTotal windows: {len(y_all)}\")\n",
    "    print(f\"Windows with actions: {len(non_none_indices)} ({len(non_none_indices)/len(y_all):.3f})\")\n",
    "else:\n",
    "    print(\"No processed data available for sanity check\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
